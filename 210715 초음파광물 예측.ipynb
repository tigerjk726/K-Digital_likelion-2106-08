{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a22ea3bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.029164</td>\n",
       "      <td>0.038437</td>\n",
       "      <td>0.043832</td>\n",
       "      <td>0.053892</td>\n",
       "      <td>0.075202</td>\n",
       "      <td>0.104570</td>\n",
       "      <td>0.121747</td>\n",
       "      <td>0.134799</td>\n",
       "      <td>0.178003</td>\n",
       "      <td>0.208259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016069</td>\n",
       "      <td>0.013420</td>\n",
       "      <td>0.010709</td>\n",
       "      <td>0.010941</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.007820</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>0.006507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.022991</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.038428</td>\n",
       "      <td>0.046528</td>\n",
       "      <td>0.055552</td>\n",
       "      <td>0.059105</td>\n",
       "      <td>0.061788</td>\n",
       "      <td>0.085152</td>\n",
       "      <td>0.118387</td>\n",
       "      <td>0.134416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.007301</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>0.005736</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.006470</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>0.005031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.013350</td>\n",
       "      <td>0.016450</td>\n",
       "      <td>0.018950</td>\n",
       "      <td>0.024375</td>\n",
       "      <td>0.038050</td>\n",
       "      <td>0.067025</td>\n",
       "      <td>0.080900</td>\n",
       "      <td>0.080425</td>\n",
       "      <td>0.097025</td>\n",
       "      <td>0.111275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008425</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>0.005375</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.034300</td>\n",
       "      <td>0.044050</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.092150</td>\n",
       "      <td>0.106950</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>0.152250</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013900</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.009550</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.006850</td>\n",
       "      <td>0.005950</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.035550</td>\n",
       "      <td>0.047950</td>\n",
       "      <td>0.057950</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.100275</td>\n",
       "      <td>0.134125</td>\n",
       "      <td>0.154000</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.233425</td>\n",
       "      <td>0.268700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>0.016725</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.014500</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.010575</td>\n",
       "      <td>0.010425</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.010325</td>\n",
       "      <td>0.008525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.137100</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.305900</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.382300</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>0.682800</td>\n",
       "      <td>0.710600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.043900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.029164    0.038437    0.043832    0.053892    0.075202    0.104570   \n",
       "std      0.022991    0.032960    0.038428    0.046528    0.055552    0.059105   \n",
       "min      0.001500    0.000600    0.001500    0.005800    0.006700    0.010200   \n",
       "25%      0.013350    0.016450    0.018950    0.024375    0.038050    0.067025   \n",
       "50%      0.022800    0.030800    0.034300    0.044050    0.062500    0.092150   \n",
       "75%      0.035550    0.047950    0.057950    0.064500    0.100275    0.134125   \n",
       "max      0.137100    0.233900    0.305900    0.426400    0.401000    0.382300   \n",
       "\n",
       "               6           7           8           9   ...          50  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  ...  208.000000   \n",
       "mean     0.121747    0.134799    0.178003    0.208259  ...    0.016069   \n",
       "std      0.061788    0.085152    0.118387    0.134416  ...    0.012008   \n",
       "min      0.003300    0.005500    0.007500    0.011300  ...    0.000000   \n",
       "25%      0.080900    0.080425    0.097025    0.111275  ...    0.008425   \n",
       "50%      0.106950    0.112100    0.152250    0.182400  ...    0.013900   \n",
       "75%      0.154000    0.169600    0.233425    0.268700  ...    0.020825   \n",
       "max      0.372900    0.459000    0.682800    0.710600  ...    0.100400   \n",
       "\n",
       "               51          52          53          54          55          56  \\\n",
       "count  208.000000  208.000000  208.000000  208.000000  208.000000  208.000000   \n",
       "mean     0.013420    0.010709    0.010941    0.009290    0.008222    0.007820   \n",
       "std      0.009634    0.007060    0.007301    0.007088    0.005736    0.005785   \n",
       "min      0.000800    0.000500    0.001000    0.000600    0.000400    0.000300   \n",
       "25%      0.007275    0.005075    0.005375    0.004150    0.004400    0.003700   \n",
       "50%      0.011400    0.009550    0.009300    0.007500    0.006850    0.005950   \n",
       "75%      0.016725    0.014900    0.014500    0.012100    0.010575    0.010425   \n",
       "max      0.070900    0.039000    0.035200    0.044700    0.039400    0.035500   \n",
       "\n",
       "               57          58          59  \n",
       "count  208.000000  208.000000  208.000000  \n",
       "mean     0.007949    0.007941    0.006507  \n",
       "std      0.006470    0.006181    0.005031  \n",
       "min      0.000300    0.000100    0.000600  \n",
       "25%      0.003600    0.003675    0.003100  \n",
       "50%      0.005800    0.006400    0.005300  \n",
       "75%      0.010350    0.010325    0.008525  \n",
       "max      0.044000    0.036400    0.043900  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################\n",
    "# 광물초음파 예측\n",
    "################################\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import optimizers # lr 조정할때 쓰임\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "df = pd.read_csv('sonar.csv', header=None)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "34508bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape = (166, 60)\n",
      "x_test.shape = (42, 60)\n",
      "y_train.shape = (166, 1)\n",
      "y_test.shape = (42, 1)\n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      "Epoch 1/40\n",
      "21/21 [==============================] - 0s 474us/step - loss: 0.6779 - accuracy: 0.5817\n",
      "Epoch 2/40\n",
      "21/21 [==============================] - 0s 475us/step - loss: 0.6042 - accuracy: 0.6731\n",
      "Epoch 3/40\n",
      "21/21 [==============================] - 0s 475us/step - loss: 0.5086 - accuracy: 0.7500\n",
      "Epoch 4/40\n",
      "21/21 [==============================] - 0s 475us/step - loss: 0.4885 - accuracy: 0.7500\n",
      "Epoch 5/40\n",
      "21/21 [==============================] - 0s 475us/step - loss: 0.4432 - accuracy: 0.8029\n",
      "Epoch 6/40\n",
      "21/21 [==============================] - 0s 570us/step - loss: 0.4453 - accuracy: 0.7596\n",
      "Epoch 7/40\n",
      "21/21 [==============================] - 0s 570us/step - loss: 0.3935 - accuracy: 0.8077\n",
      "Epoch 8/40\n",
      "21/21 [==============================] - 0s 522us/step - loss: 0.3987 - accuracy: 0.7885\n",
      "Epoch 9/40\n",
      "21/21 [==============================] - 0s 617us/step - loss: 0.3654 - accuracy: 0.8413\n",
      "Epoch 10/40\n",
      "21/21 [==============================] - 0s 570us/step - loss: 0.4016 - accuracy: 0.8077\n",
      "Epoch 11/40\n",
      "21/21 [==============================] - 0s 570us/step - loss: 0.3537 - accuracy: 0.8510\n",
      "Epoch 12/40\n",
      "21/21 [==============================] - 0s 570us/step - loss: 0.4234 - accuracy: 0.7885\n",
      "Epoch 13/40\n",
      "21/21 [==============================] - 0s 522us/step - loss: 0.3773 - accuracy: 0.8269\n",
      "Epoch 14/40\n",
      "21/21 [==============================] - 0s 570us/step - loss: 0.3312 - accuracy: 0.8413\n",
      "Epoch 15/40\n",
      "21/21 [==============================] - 0s 570us/step - loss: 0.3287 - accuracy: 0.8558\n",
      "Epoch 16/40\n",
      "21/21 [==============================] - 0s 522us/step - loss: 0.3032 - accuracy: 0.8750\n",
      "Epoch 17/40\n",
      "21/21 [==============================] - 0s 475us/step - loss: 0.2759 - accuracy: 0.8702\n",
      "Epoch 18/40\n",
      "21/21 [==============================] - 0s 475us/step - loss: 0.2713 - accuracy: 0.8702\n",
      "Epoch 19/40\n",
      "21/21 [==============================] - 0s 475us/step - loss: 0.2913 - accuracy: 0.8606\n",
      "Epoch 20/40\n",
      "21/21 [==============================] - 0s 570us/step - loss: 0.2700 - accuracy: 0.9038\n",
      "Epoch 21/40\n",
      "21/21 [==============================] - 0s 665us/step - loss: 0.2402 - accuracy: 0.9183\n",
      "Epoch 22/40\n",
      "21/21 [==============================] - 0s 522us/step - loss: 0.2274 - accuracy: 0.9183\n",
      "Epoch 23/40\n",
      "21/21 [==============================] - 0s 570us/step - loss: 0.2443 - accuracy: 0.8990\n",
      "Epoch 24/40\n",
      "21/21 [==============================] - 0s 570us/step - loss: 0.2137 - accuracy: 0.9135\n",
      "Epoch 25/40\n",
      "21/21 [==============================] - 0s 475us/step - loss: 0.2367 - accuracy: 0.9135\n",
      "Epoch 26/40\n",
      "21/21 [==============================] - 0s 522us/step - loss: 0.2182 - accuracy: 0.9135\n",
      "Epoch 27/40\n",
      "21/21 [==============================] - 0s 522us/step - loss: 0.2128 - accuracy: 0.8990\n",
      "Epoch 28/40\n",
      "21/21 [==============================] - 0s 522us/step - loss: 0.2334 - accuracy: 0.8942\n",
      "Epoch 29/40\n",
      "21/21 [==============================] - 0s 475us/step - loss: 0.1746 - accuracy: 0.9327\n",
      "Epoch 30/40\n",
      "21/21 [==============================] - 0s 617us/step - loss: 0.1826 - accuracy: 0.9279\n",
      "Epoch 31/40\n",
      "21/21 [==============================] - 0s 522us/step - loss: 0.2013 - accuracy: 0.9183\n",
      "Epoch 32/40\n",
      "21/21 [==============================] - 0s 570us/step - loss: 0.1717 - accuracy: 0.9327\n",
      "Epoch 33/40\n",
      "21/21 [==============================] - 0s 522us/step - loss: 0.1745 - accuracy: 0.9327\n",
      "Epoch 34/40\n",
      "21/21 [==============================] - 0s 570us/step - loss: 0.1704 - accuracy: 0.9231\n",
      "Epoch 35/40\n",
      "21/21 [==============================] - 0s 617us/step - loss: 0.1406 - accuracy: 0.9471\n",
      "Epoch 36/40\n",
      "21/21 [==============================] - 0s 522us/step - loss: 0.1762 - accuracy: 0.9183\n",
      "Epoch 37/40\n",
      "21/21 [==============================] - 0s 475us/step - loss: 0.1775 - accuracy: 0.9279\n",
      "Epoch 38/40\n",
      "21/21 [==============================] - 0s 522us/step - loss: 0.1869 - accuracy: 0.9279\n",
      "Epoch 39/40\n",
      "21/21 [==============================] - 0s 570us/step - loss: 0.1646 - accuracy: 0.9327\n",
      "Epoch 40/40\n",
      "21/21 [==============================] - 0s 522us/step - loss: 0.1406 - accuracy: 0.9423\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_51 (Dense)             (None, 100)               6100      \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 6,201\n",
      "Trainable params: 6,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_test_function.<locals>.test_function at 0x000002AC8DB61D30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 998us/step - loss: 0.1106 - accuracy: 0.9762\n",
      "accuracy : 97.6190%\n"
     ]
    }
   ],
   "source": [
    "dataset = df.values \n",
    "# astype 없으면 model.fit에서 unsupported objuect type float error 발생\n",
    "x = dataset[:,:60].astype(float)\n",
    "\n",
    "y = dataset[:,60]\n",
    "\n",
    "e = LabelEncoder()\n",
    "y = e.fit_transform(y)\n",
    "y = y.reshape(-1,1)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=0)\n",
    "print(\"x_train.shape =\", x_train.shape)\n",
    "print(\"x_test.shape =\", x_test.shape)\n",
    "print(\"y_train.shape =\", y_train.shape)\n",
    "print(\"y_test.shape =\", y_test.shape)\n",
    "print(y_test[0:5])\n",
    "      \n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=60, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 모델 학습과정 설정 \n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(lr=0.01), metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습시키기\n",
    "model.fit(x,y, epochs=40, batch_size=10)\n",
    "model.summary()\n",
    "#모델 평가하기\n",
    "score = model.evaluate(x_test,y_test)\n",
    "\n",
    "print(\"%s : %.4f%%\" %(model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "607ee2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape = (145, 60)\n",
      "x_test.shape = (63, 60)\n",
      "y_train.shape = (145,)\n",
      "y_test.shape = (63,)\n",
      "[1 1 1 1 0]\n",
      "Epoch 1/50\n",
      "15/15 [==============================] - 0s 530us/step - loss: 0.6872 - accuracy: 0.5586\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 0s 532us/step - loss: 0.6174 - accuracy: 0.6759\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 0s 532us/step - loss: 0.5411 - accuracy: 0.7310\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 0s 532us/step - loss: 0.4852 - accuracy: 0.7448\n",
      "Epoch 5/50\n",
      "15/15 [==============================] - 0s 532us/step - loss: 0.4505 - accuracy: 0.7724\n",
      "Epoch 6/50\n",
      "15/15 [==============================] - 0s 532us/step - loss: 0.5057 - accuracy: 0.7448\n",
      "Epoch 7/50\n",
      "15/15 [==============================] - 0s 532us/step - loss: 0.5161 - accuracy: 0.7310\n",
      "Epoch 8/50\n",
      "15/15 [==============================] - 0s 532us/step - loss: 0.5253 - accuracy: 0.7448\n",
      "Epoch 9/50\n",
      "15/15 [==============================] - 0s 665us/step - loss: 0.4203 - accuracy: 0.8207\n",
      "Epoch 10/50\n",
      "15/15 [==============================] - 0s 532us/step - loss: 0.3716 - accuracy: 0.8207\n",
      "Epoch 11/50\n",
      "15/15 [==============================] - 0s 731us/step - loss: 0.3680 - accuracy: 0.8207\n",
      "Epoch 12/50\n",
      "15/15 [==============================] - 0s 665us/step - loss: 0.3619 - accuracy: 0.8414\n",
      "Epoch 13/50\n",
      "15/15 [==============================] - 0s 598us/step - loss: 0.3382 - accuracy: 0.8621\n",
      "Epoch 14/50\n",
      "15/15 [==============================] - 0s 598us/step - loss: 0.4288 - accuracy: 0.7862\n",
      "Epoch 15/50\n",
      "15/15 [==============================] - 0s 731us/step - loss: 0.3823 - accuracy: 0.8276\n",
      "Epoch 16/50\n",
      "15/15 [==============================] - 0s 665us/step - loss: 0.3142 - accuracy: 0.8621\n",
      "Epoch 17/50\n",
      "15/15 [==============================] - 0s 598us/step - loss: 0.3025 - accuracy: 0.8483\n",
      "Epoch 18/50\n",
      "15/15 [==============================] - 0s 598us/step - loss: 0.3039 - accuracy: 0.8414\n",
      "Epoch 19/50\n",
      "15/15 [==============================] - 0s 864us/step - loss: 0.2915 - accuracy: 0.8759\n",
      "Epoch 20/50\n",
      "15/15 [==============================] - 0s 731us/step - loss: 0.2537 - accuracy: 0.8621\n",
      "Epoch 21/50\n",
      "15/15 [==============================] - 0s 598us/step - loss: 0.3253 - accuracy: 0.8621\n",
      "Epoch 22/50\n",
      "15/15 [==============================] - 0s 598us/step - loss: 0.3141 - accuracy: 0.8414\n",
      "Epoch 23/50\n",
      "15/15 [==============================] - 0s 598us/step - loss: 0.2391 - accuracy: 0.8897\n",
      "Epoch 24/50\n",
      "15/15 [==============================] - 0s 532us/step - loss: 0.2051 - accuracy: 0.9103\n",
      "Epoch 25/50\n",
      "15/15 [==============================] - 0s 665us/step - loss: 0.2071 - accuracy: 0.8966\n",
      "Epoch 26/50\n",
      "15/15 [==============================] - 0s 598us/step - loss: 0.2309 - accuracy: 0.8828\n",
      "Epoch 27/50\n",
      "15/15 [==============================] - 0s 731us/step - loss: 0.2158 - accuracy: 0.8966\n",
      "Epoch 28/50\n",
      "15/15 [==============================] - 0s 665us/step - loss: 0.2702 - accuracy: 0.8828\n",
      "Epoch 29/50\n",
      "15/15 [==============================] - 0s 532us/step - loss: 0.1992 - accuracy: 0.9172\n",
      "Epoch 30/50\n",
      "15/15 [==============================] - 0s 665us/step - loss: 0.1947 - accuracy: 0.9241\n",
      "Epoch 31/50\n",
      "15/15 [==============================] - 0s 598us/step - loss: 0.1302 - accuracy: 0.9586\n",
      "Epoch 32/50\n",
      "15/15 [==============================] - 0s 665us/step - loss: 0.1106 - accuracy: 0.9586\n",
      "Epoch 33/50\n",
      "15/15 [==============================] - 0s 598us/step - loss: 0.0810 - accuracy: 0.9724\n",
      "Epoch 34/50\n",
      "15/15 [==============================] - 0s 598us/step - loss: 0.0945 - accuracy: 0.9724\n",
      "Epoch 35/50\n",
      "15/15 [==============================] - 0s 598us/step - loss: 0.0870 - accuracy: 0.9793\n",
      "Epoch 36/50\n",
      "15/15 [==============================] - 0s 665us/step - loss: 0.0776 - accuracy: 0.9793\n",
      "Epoch 37/50\n",
      "15/15 [==============================] - 0s 731us/step - loss: 0.0651 - accuracy: 0.9793\n",
      "Epoch 38/50\n",
      "15/15 [==============================] - 0s 665us/step - loss: 0.0830 - accuracy: 0.9793\n",
      "Epoch 39/50\n",
      "15/15 [==============================] - 0s 665us/step - loss: 0.0488 - accuracy: 0.9862\n",
      "Epoch 40/50\n",
      "15/15 [==============================] - 0s 532us/step - loss: 0.0702 - accuracy: 0.9793\n",
      "Epoch 41/50\n",
      "15/15 [==============================] - 0s 598us/step - loss: 0.0657 - accuracy: 0.9724\n",
      "Epoch 42/50\n",
      "15/15 [==============================] - 0s 532us/step - loss: 0.0526 - accuracy: 0.9862\n",
      "Epoch 43/50\n",
      "15/15 [==============================] - 0s 665us/step - loss: 0.0458 - accuracy: 0.9793\n",
      "Epoch 44/50\n",
      "15/15 [==============================] - 0s 731us/step - loss: 0.1226 - accuracy: 0.9379\n",
      "Epoch 45/50\n",
      "15/15 [==============================] - 0s 598us/step - loss: 0.0917 - accuracy: 0.9586\n",
      "Epoch 46/50\n",
      "15/15 [==============================] - 0s 532us/step - loss: 0.1835 - accuracy: 0.9379\n",
      "Epoch 47/50\n",
      "15/15 [==============================] - 0s 665us/step - loss: 0.1547 - accuracy: 0.9379\n",
      "Epoch 48/50\n",
      "15/15 [==============================] - 0s 598us/step - loss: 0.2029 - accuracy: 0.9172\n",
      "Epoch 49/50\n",
      "15/15 [==============================] - 0s 598us/step - loss: 0.0551 - accuracy: 0.9862\n",
      "Epoch 50/50\n",
      "15/15 [==============================] - 0s 665us/step - loss: 0.0605 - accuracy: 0.9862\n",
      "1/5 [=====>........................] - ETA: 0s - loss: 0.0960 - accuracy: 0.9688WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "5/5 [==============================] - 0s 598us/step - loss: 0.0438 - accuracy: 0.9931\n",
      "accuracy : 99.3103%\n",
      "2/2 [==============================] - 0s 499us/step - loss: 0.8470 - accuracy: 0.7937\n",
      "accuracy : 79.3651%\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "# 훈련 검증셋 연습\n",
    "################################\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import optimizers # lr 조정할때 쓰임\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "df = pd.read_csv('sonar.csv', header=None)\n",
    "\n",
    "dataset = df.values \n",
    "# astype 없으면 model.fit에서 unsupported objuect type float error 발생\n",
    "x = dataset[:,:60].astype(float)\n",
    "y = dataset[:,60]\n",
    "\n",
    "e = LabelEncoder()\n",
    "y = e.fit_transform(y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state=0)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(40, input_dim=60, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "print(\"x_train.shape =\", x_train.shape)\n",
    "print(\"x_test.shape =\", x_test.shape)\n",
    "print(\"y_train.shape =\", y_train.shape)\n",
    "print(\"y_test.shape =\", y_test.shape)\n",
    "print(y_test[0:5])\n",
    "\n",
    "# 모델 학습과정 설정 \n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(lr=0.01), metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train,y_train, epochs=50, batch_size=10)\n",
    "score = model.evaluate(x_train,y_train)\n",
    "print(\"%s : %.4f%%\" %(model.metrics_names[1], score[1]*100))\n",
    "\n",
    "score1 = model.evaluate(x_test,y_test)\n",
    "print(\"%s : %.4f%%\" %(model.metrics_names[1], score1[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55433714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape = (105, 4)\n",
      "x_test.shape = (45, 4)\n",
      "y_train.shape = (105, 3)\n",
      "y_test.shape = (45, 3)\n",
      "[[0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]]\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 452us/step - loss: 2.3305 - accuracy: 0.3714\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 2.0810 - accuracy: 0.3714\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 1.7911 - accuracy: 0.3810\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 1.5280 - accuracy: 0.5048\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 362us/step - loss: 1.2800 - accuracy: 0.6762\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 1.0400 - accuracy: 0.6952\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.8745 - accuracy: 0.6952\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.7604 - accuracy: 0.6952\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.6970 - accuracy: 0.6952\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.6667 - accuracy: 0.6952\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 361us/step - loss: 0.6474 - accuracy: 0.7048\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.6325 - accuracy: 0.7048\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.6186 - accuracy: 0.7048\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.6067 - accuracy: 0.7048\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 543us/step - loss: 0.5963 - accuracy: 0.7048\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 362us/step - loss: 0.5862 - accuracy: 0.7048\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.5752 - accuracy: 0.7048\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.5678 - accuracy: 0.7143\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.5553 - accuracy: 0.7238\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.5462 - accuracy: 0.7333\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.5376 - accuracy: 0.7333\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.5308 - accuracy: 0.7333\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.5213 - accuracy: 0.7333\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.5145 - accuracy: 0.7333\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.5074 - accuracy: 0.7333\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4986 - accuracy: 0.7333\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4921 - accuracy: 0.7429\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 454us/step - loss: 0.4856 - accuracy: 0.7524\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4799 - accuracy: 0.8095\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4729 - accuracy: 0.8476\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4659 - accuracy: 0.7714\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.4625 - accuracy: 0.7333\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4562 - accuracy: 0.8000\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.4498 - accuracy: 0.8857\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.4435 - accuracy: 0.8667\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.4384 - accuracy: 0.8000\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 454us/step - loss: 0.4334 - accuracy: 0.8667\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.4273 - accuracy: 0.8762\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.4248 - accuracy: 0.8952\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4158 - accuracy: 0.8952\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 454us/step - loss: 0.4120 - accuracy: 0.8762\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 635us/step - loss: 0.4065 - accuracy: 0.8762\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.4003 - accuracy: 0.8762\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.3935 - accuracy: 0.9048\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.3880 - accuracy: 0.9524\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 454us/step - loss: 0.3798 - accuracy: 0.9333\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 454us/step - loss: 0.3750 - accuracy: 0.9143\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.3709 - accuracy: 0.9143\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.3649 - accuracy: 0.9143\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.3619 - accuracy: 0.9429\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 725us/step - loss: 0.3550 - accuracy: 0.9429\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 634us/step - loss: 0.3511 - accuracy: 0.9429\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.3462 - accuracy: 0.9333\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.3423 - accuracy: 0.9333\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.3390 - accuracy: 0.9238\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 454us/step - loss: 0.3343 - accuracy: 0.9333\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 454us/step - loss: 0.3292 - accuracy: 0.9524\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 454us/step - loss: 0.3255 - accuracy: 0.9619\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 454us/step - loss: 0.3229 - accuracy: 0.9619\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 454us/step - loss: 0.3172 - accuracy: 0.9524\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.3159 - accuracy: 0.9524\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.3104 - accuracy: 0.9524\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 454us/step - loss: 0.3063 - accuracy: 0.9524\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.3043 - accuracy: 0.9619\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 454us/step - loss: 0.3044 - accuracy: 0.9429\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.2985 - accuracy: 0.9619\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 454us/step - loss: 0.2926 - accuracy: 0.9619\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 454us/step - loss: 0.2910 - accuracy: 0.9619\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 454us/step - loss: 0.2861 - accuracy: 0.9619\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.2839 - accuracy: 0.9619\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.2847 - accuracy: 0.9619\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 545us/step - loss: 0.2763 - accuracy: 0.9619\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.2733 - accuracy: 0.9619\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.2701 - accuracy: 0.9619\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.2674 - accuracy: 0.9619\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.2665 - accuracy: 0.9619\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.2609 - accuracy: 0.9619\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 454us/step - loss: 0.2594 - accuracy: 0.9619\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 453us/step - loss: 0.2566 - accuracy: 0.9619\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 544us/step - loss: 0.2544 - accuracy: 0.9619\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.2522 - accuracy: 0.9619\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 454us/step - loss: 0.2483 - accuracy: 0.9619\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.2453 - accuracy: 0.9619\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.2433 - accuracy: 0.9619\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.2399 - accuracy: 0.9619\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.2376 - accuracy: 0.9619\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.2367 - accuracy: 0.9619\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.2348 - accuracy: 0.9619\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.2336 - accuracy: 0.9619\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.2274 - accuracy: 0.9619\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.2279 - accuracy: 0.9619\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.2233 - accuracy: 0.9619\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 363us/step - loss: 0.2230 - accuracy: 0.9619\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.2189 - accuracy: 0.9619\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.2172 - accuracy: 0.9619\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 362us/step - loss: 0.2147 - accuracy: 0.9619\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.2129 - accuracy: 0.9714\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.2106 - accuracy: 0.9619\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 454us/step - loss: 0.2094 - accuracy: 0.9619\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 453us/step - loss: 0.2132 - accuracy: 0.9619\n",
      "4/4 [==============================] - 0s 499us/step - loss: 0.2056 - accuracy: 0.9714\n",
      "accuracy : 97.1429%\n",
      "2/2 [==============================] - 0s 499us/step - loss: 0.2357 - accuracy: 0.9778\n",
      "accuracy : 97.7778%\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "# 아이리스 훈련 검증셋\n",
    "################################\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import optimizers # lr 조정할때 쓰임\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "df = pd.read_csv('iris.csv', names = ['sepal_length','sepal_width','petal_length','petal_width','species'])\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "dataset = df.values\n",
    "X = dataset[:,:-1].astype(float)\n",
    "Y_obj = dataset[:,4]\n",
    "\n",
    "#문자열을 숫자로 변환 (3품종을 1,2,3 으로 변환 하고 keras.utils.to_categorical로 [0,0,1] or [ 0,1,0] or [1,0,0] 으로 바꿈\n",
    "# 그래서 sotfmax는 각 데이터의 합이 1로 만들어서 원핫인코딩이라고함 (가장 큰수를 1로 함)\n",
    "\n",
    "e = LabelEncoder()\n",
    "e.fit(Y_obj)\n",
    "Y = e.transform(Y_obj)\n",
    "Y_encoded = tf.keras.utils.to_categorical(Y)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=4, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y_encoded, test_size = 0.3, random_state=0)\n",
    "\n",
    "#test_size: 테스트 셋 구성의 비율을 나타냅니다. \n",
    "#train_size의 옵션과 반대 관계에 있는 옵션 값이며, 주로 test_size를 지정해 줍니다. \n",
    "#0.2는 전체 데이터 셋의 20%를 test (validation) 셋으로 지정하겠다는 의미입니다. \n",
    "#default 값은 0.25 입니다.\n",
    "#shuffle: default=True 입니다. split을 해주기 이전에 섞을건지 여부입니다. 보통은 default 값으로 놔둡니다.\n",
    "#stratify: default=None 입니다. classification을 다룰 때 매우 중요한 옵션값입니다. \n",
    "#stratify 값을 target으로 지정해주면 각각의 class 비율(ratio)을 train / validation에 유지해 줍니다. \n",
    "#(한 쪽에 쏠려서 분배되는 것을 방지합니다) \n",
    "#random_state: 세트를 섞을 때 해당 int 값을 보고 섞으며, 하이퍼 파라미터를 튜닝시 이 값을 고정해두고 \n",
    "#튜닝해야 매번 데이터셋이 변경되는 것을 방지할 수 있습니다.\n",
    "    \n",
    "print(\"x_train.shape =\", x_train.shape)\n",
    "print(\"x_test.shape =\", x_test.shape)\n",
    "print(\"y_train.shape =\", y_train.shape)\n",
    "print(\"y_test.shape =\", y_test.shape)\n",
    "print(y_test[0:5])\n",
    "\n",
    "# 모델 학습과정 설정 \n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=0.001), metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train,y_train, epochs=100, batch_size=10)\n",
    "\n",
    "# 모델을 컴퓨터에 저장\n",
    "model.save('my_model.h5')\n",
    "\n",
    "# 모델을 컴퓨터에 불러오기\n",
    "model = keras.models.load_model('my_model.h5')\n",
    "\n",
    "print(\"%s : %.4f%%\" %(model.metrics_names[1], model.evaluate(x_train,y_train)[1]*100))\n",
    "\n",
    "print(\"%s : %.4f%%\" %(model.metrics_names[1], model.evaluate(x_test,y_test)[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af7d0bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
