{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7ef5fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers # lr 조정할때 쓰임\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_gen = pd.read_csv('2.Kaggle/210722 titanic/gender_submission.csv', header=0)\n",
    "df_train = pd.read_csv('2.Kaggle/210722 titanic/train.csv', header=0)\n",
    "df_test = pd.read_csv('2.Kaggle/210722 titanic/test.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b64aa10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.info()\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29eb778c",
   "metadata": {},
   "source": [
    "**결측치 개수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fddd9043",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0d45c0",
   "metadata": {},
   "source": [
    "**단일값 삭제(Pairwise) 특정 열들중에 결측치가 있을 경우에 해당 행을 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "010db1f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age              0\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          529\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_train.dropna(subset=['Age'])\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6196edc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = df.drop(['Cabin','Name','Ticket'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd0baa9",
   "metadata": {},
   "source": [
    "**astype(‘category’).cat.codes numerical 데이터로 변경하고 싶은 categorical 컬럼을 정한 뒤,\n",
    "categorical 형 column으로 강제 형변환을 시키고 cat.codes를 호출해 주면 자동으로 숫자형 리턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8cbccad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Embarked'] = df['Embarked'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8006b2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sex'] = df['Sex'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fa45024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 714 entries, 0 to 890\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  714 non-null    int64  \n",
      " 1   Survived     714 non-null    int64  \n",
      " 2   Pclass       714 non-null    int64  \n",
      " 3   Sex          714 non-null    int8   \n",
      " 4   Age          714 non-null    float64\n",
      " 5   SibSp        714 non-null    int64  \n",
      " 6   Parch        714 non-null    int64  \n",
      " 7   Fare         714 non-null    float64\n",
      " 8   Embarked     714 non-null    int8   \n",
      "dtypes: float64(2), int64(5), int8(2)\n",
      "memory usage: 46.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56baee7",
   "metadata": {},
   "source": [
    "**그럼 이제 모든 값의 데이터를 int or float으로 변경완료\n",
    "데이터 x,y값 설정, standardScaler로 그래프 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22c92f60",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age             86\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             1\n",
       "Cabin          327\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d00efdce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>120.810458</td>\n",
       "      <td>0.481622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>892.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>996.250000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1204.750000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived\n",
       "count   418.000000  418.000000\n",
       "mean   1100.500000    0.363636\n",
       "std     120.810458    0.481622\n",
       "min     892.000000    0.000000\n",
       "25%     996.250000    0.000000\n",
       "50%    1100.500000    0.000000\n",
       "75%    1204.750000    1.000000\n",
       "max    1309.000000    1.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gen.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29c1cc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Survived'] = df_gen['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db0e79ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Sex'] = df_test['Sex'].astype('category').cat.codes\n",
    "df_test['Embarked'] = df_test['Embarked'].astype('category').cat.codes\n",
    "df_test = df_test.drop(['Cabin','Name','Ticket'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a530221b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_test = df_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d75e3272",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df_test[[\"PassengerId\", \"Pclass\", \"Sex\",\"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f9cacd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = df_test[[\"Survived\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c6ad88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = df[[\"PassengerId\", \"Pclass\", \"Sex\",\"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]]\n",
    "y = pd.DataFrame(df[\"Survived\"])\n",
    "\n",
    "x_ss = StandardScaler().fit_transform(x)\n",
    "y_ss = StandardScaler().fit_transform(y)\n",
    "plt.boxplot(x_ss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a25e7e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 1.1005 - accuracy: 0.5448\n",
      "Epoch 2/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.7522 - accuracy: 0.5994\n",
      "Epoch 3/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.6746 - accuracy: 0.6443\n",
      "Epoch 4/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.6790 - accuracy: 0.6317\n",
      "Epoch 5/300\n",
      "72/72 [==============================] - 0s 582us/step - loss: 0.6438 - accuracy: 0.6373\n",
      "Epoch 6/300\n",
      "72/72 [==============================] - 0s 471us/step - loss: 0.6345 - accuracy: 0.6681\n",
      "Epoch 7/300\n",
      "72/72 [==============================] - 0s 471us/step - loss: 0.6097 - accuracy: 0.6835\n",
      "Epoch 8/300\n",
      "72/72 [==============================] - 0s 457us/step - loss: 0.6228 - accuracy: 0.6737\n",
      "Epoch 9/300\n",
      "72/72 [==============================] - 0s 540us/step - loss: 0.6107 - accuracy: 0.6695\n",
      "Epoch 10/300\n",
      "72/72 [==============================] - 0s 471us/step - loss: 0.6359 - accuracy: 0.6625\n",
      "Epoch 11/300\n",
      "72/72 [==============================] - 0s 457us/step - loss: 0.6189 - accuracy: 0.6807\n",
      "Epoch 12/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.6037 - accuracy: 0.6807\n",
      "Epoch 13/300\n",
      "72/72 [==============================] - 0s 471us/step - loss: 0.5952 - accuracy: 0.7101\n",
      "Epoch 14/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.5882 - accuracy: 0.6961\n",
      "Epoch 15/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.5853 - accuracy: 0.6835\n",
      "Epoch 16/300\n",
      "72/72 [==============================] - 0s 526us/step - loss: 0.5872 - accuracy: 0.6975\n",
      "Epoch 17/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.5776 - accuracy: 0.7045\n",
      "Epoch 18/300\n",
      "72/72 [==============================] - 0s 651us/step - loss: 0.5966 - accuracy: 0.7003\n",
      "Epoch 19/300\n",
      "72/72 [==============================] - 0s 942us/step - loss: 0.5750 - accuracy: 0.7171\n",
      "Epoch 20/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.5738 - accuracy: 0.7115\n",
      "Epoch 21/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.5695 - accuracy: 0.7213\n",
      "Epoch 22/300\n",
      "72/72 [==============================] - 0s 471us/step - loss: 0.5903 - accuracy: 0.6947\n",
      "Epoch 23/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.5796 - accuracy: 0.6961\n",
      "Epoch 24/300\n",
      "72/72 [==============================] - ETA: 0s - loss: 0.5557 - accuracy: 0.70 - 0s 471us/step - loss: 0.5710 - accuracy: 0.7143\n",
      "Epoch 25/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.5692 - accuracy: 0.7227\n",
      "Epoch 26/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.5550 - accuracy: 0.7087\n",
      "Epoch 27/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.5440 - accuracy: 0.7199\n",
      "Epoch 28/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.5850 - accuracy: 0.6989\n",
      "Epoch 29/300\n",
      "72/72 [==============================] - 0s 526us/step - loss: 0.5500 - accuracy: 0.7171\n",
      "Epoch 30/300\n",
      "72/72 [==============================] - 0s 471us/step - loss: 0.5591 - accuracy: 0.7311\n",
      "Epoch 31/300\n",
      "72/72 [==============================] - 0s 457us/step - loss: 0.5568 - accuracy: 0.7101\n",
      "Epoch 32/300\n",
      "72/72 [==============================] - 0s 471us/step - loss: 0.5592 - accuracy: 0.7199\n",
      "Epoch 33/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.5846 - accuracy: 0.6961\n",
      "Epoch 34/300\n",
      "72/72 [==============================] - 0s 471us/step - loss: 0.5772 - accuracy: 0.7003\n",
      "Epoch 35/300\n",
      "72/72 [==============================] - 0s 457us/step - loss: 0.5855 - accuracy: 0.6835\n",
      "Epoch 36/300\n",
      "72/72 [==============================] - 0s 471us/step - loss: 0.5596 - accuracy: 0.6933\n",
      "Epoch 37/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.5440 - accuracy: 0.7325\n",
      "Epoch 38/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.5475 - accuracy: 0.7157\n",
      "Epoch 39/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.5265 - accuracy: 0.7395\n",
      "Epoch 40/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.5333 - accuracy: 0.7269\n",
      "Epoch 41/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.5207 - accuracy: 0.7255\n",
      "Epoch 42/300\n",
      "72/72 [==============================] - 0s 471us/step - loss: 0.5129 - accuracy: 0.7325\n",
      "Epoch 43/300\n",
      "72/72 [==============================] - 0s 471us/step - loss: 0.5242 - accuracy: 0.7353\n",
      "Epoch 44/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.5140 - accuracy: 0.7311\n",
      "Epoch 45/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.5483 - accuracy: 0.7213\n",
      "Epoch 46/300\n",
      "72/72 [==============================] - 0s 526us/step - loss: 0.5536 - accuracy: 0.7185\n",
      "Epoch 47/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.5430 - accuracy: 0.7185\n",
      "Epoch 48/300\n",
      "72/72 [==============================] - 0s 554us/step - loss: 0.5433 - accuracy: 0.7227\n",
      "Epoch 49/300\n",
      "72/72 [==============================] - 0s 540us/step - loss: 0.5226 - accuracy: 0.7535\n",
      "Epoch 50/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.5326 - accuracy: 0.7507\n",
      "Epoch 51/300\n",
      "72/72 [==============================] - 0s 471us/step - loss: 0.5269 - accuracy: 0.7479\n",
      "Epoch 52/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.5383 - accuracy: 0.7255\n",
      "Epoch 53/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.5046 - accuracy: 0.7535\n",
      "Epoch 54/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.4928 - accuracy: 0.7619\n",
      "Epoch 55/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.4918 - accuracy: 0.7577\n",
      "Epoch 56/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.4987 - accuracy: 0.7717\n",
      "Epoch 57/300\n",
      "72/72 [==============================] - 0s 471us/step - loss: 0.5602 - accuracy: 0.7171\n",
      "Epoch 58/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.5131 - accuracy: 0.7437\n",
      "Epoch 59/300\n",
      "72/72 [==============================] - 0s 582us/step - loss: 0.5017 - accuracy: 0.7647\n",
      "Epoch 60/300\n",
      "72/72 [==============================] - 0s 582us/step - loss: 0.4917 - accuracy: 0.7661\n",
      "Epoch 61/300\n",
      "72/72 [==============================] - 0s 596us/step - loss: 0.4938 - accuracy: 0.7745\n",
      "Epoch 62/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.4950 - accuracy: 0.7717\n",
      "Epoch 63/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.4910 - accuracy: 0.7717\n",
      "Epoch 64/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.5074 - accuracy: 0.7605\n",
      "Epoch 65/300\n",
      "72/72 [==============================] - 0s 471us/step - loss: 0.4872 - accuracy: 0.7857\n",
      "Epoch 66/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.4855 - accuracy: 0.7815\n",
      "Epoch 67/300\n",
      "72/72 [==============================] - 0s 471us/step - loss: 0.4925 - accuracy: 0.7815\n",
      "Epoch 68/300\n",
      "72/72 [==============================] - 0s 457us/step - loss: 0.4933 - accuracy: 0.7745\n",
      "Epoch 69/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.5418 - accuracy: 0.7269\n",
      "Epoch 70/300\n",
      "72/72 [==============================] - 0s 457us/step - loss: 0.4975 - accuracy: 0.7647\n",
      "Epoch 71/300\n",
      "72/72 [==============================] - 0s 471us/step - loss: 0.4831 - accuracy: 0.7619\n",
      "Epoch 72/300\n",
      "72/72 [==============================] - 0s 471us/step - loss: 0.4796 - accuracy: 0.7675\n",
      "Epoch 73/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.5008 - accuracy: 0.7619\n",
      "Epoch 74/300\n",
      "72/72 [==============================] - 0s 526us/step - loss: 0.4812 - accuracy: 0.7871\n",
      "Epoch 75/300\n",
      "72/72 [==============================] - 0s 582us/step - loss: 0.4797 - accuracy: 0.7647\n",
      "Epoch 76/300\n",
      "72/72 [==============================] - 0s 540us/step - loss: 0.4740 - accuracy: 0.7731\n",
      "Epoch 77/300\n",
      "72/72 [==============================] - 0s 526us/step - loss: 0.4858 - accuracy: 0.7913\n",
      "Epoch 78/300\n",
      "72/72 [==============================] - 0s 540us/step - loss: 0.4815 - accuracy: 0.7759\n",
      "Epoch 79/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.4532 - accuracy: 0.8039\n",
      "Epoch 80/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.4566 - accuracy: 0.7955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/300\n",
      "72/72 [==============================] - 0s 471us/step - loss: 0.4738 - accuracy: 0.7941\n",
      "Epoch 82/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.4550 - accuracy: 0.7997\n",
      "Epoch 83/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.4660 - accuracy: 0.7997\n",
      "Epoch 84/300\n",
      "72/72 [==============================] - 0s 443us/step - loss: 0.4568 - accuracy: 0.7941\n",
      "Epoch 85/300\n",
      "72/72 [==============================] - 0s 457us/step - loss: 0.4626 - accuracy: 0.7829\n",
      "Epoch 86/300\n",
      "72/72 [==============================] - 0s 457us/step - loss: 0.4634 - accuracy: 0.7829\n",
      "Epoch 87/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.4766 - accuracy: 0.7843\n",
      "Epoch 88/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.4659 - accuracy: 0.7899\n",
      "Epoch 89/300\n",
      "72/72 [==============================] - 0s 609us/step - loss: 0.4572 - accuracy: 0.7955\n",
      "Epoch 90/300\n",
      "72/72 [==============================] - 0s 720us/step - loss: 0.4579 - accuracy: 0.7815\n",
      "Epoch 91/300\n",
      "72/72 [==============================] - 0s 637us/step - loss: 0.4655 - accuracy: 0.7829\n",
      "Epoch 92/300\n",
      "72/72 [==============================] - 0s 734us/step - loss: 0.4458 - accuracy: 0.7941\n",
      "Epoch 93/300\n",
      "72/72 [==============================] - 0s 776us/step - loss: 0.4414 - accuracy: 0.8053\n",
      "Epoch 94/300\n",
      "72/72 [==============================] - 0s 859us/step - loss: 0.4464 - accuracy: 0.7997\n",
      "Epoch 95/300\n",
      "72/72 [==============================] - 0s 623us/step - loss: 0.4513 - accuracy: 0.7997\n",
      "Epoch 96/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.4479 - accuracy: 0.7941\n",
      "Epoch 97/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.4599 - accuracy: 0.7801\n",
      "Epoch 98/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.4447 - accuracy: 0.7969\n",
      "Epoch 99/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.4345 - accuracy: 0.7955\n",
      "Epoch 100/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.4325 - accuracy: 0.7969\n",
      "Epoch 101/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.4377 - accuracy: 0.8025\n",
      "Epoch 102/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.4430 - accuracy: 0.7871\n",
      "Epoch 103/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.4506 - accuracy: 0.7997\n",
      "Epoch 104/300\n",
      "72/72 [==============================] - 0s 471us/step - loss: 0.4352 - accuracy: 0.7927\n",
      "Epoch 105/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.4470 - accuracy: 0.7941\n",
      "Epoch 106/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.4558 - accuracy: 0.7899\n",
      "Epoch 107/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.4352 - accuracy: 0.8039\n",
      "Epoch 108/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.4242 - accuracy: 0.8039\n",
      "Epoch 109/300\n",
      "72/72 [==============================] - 0s 526us/step - loss: 0.4327 - accuracy: 0.7983\n",
      "Epoch 110/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.4268 - accuracy: 0.7969\n",
      "Epoch 111/300\n",
      "72/72 [==============================] - 0s 526us/step - loss: 0.4581 - accuracy: 0.7843\n",
      "Epoch 112/300\n",
      "72/72 [==============================] - 0s 526us/step - loss: 0.4685 - accuracy: 0.7927\n",
      "Epoch 113/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.4385 - accuracy: 0.7969\n",
      "Epoch 114/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.4366 - accuracy: 0.8039\n",
      "Epoch 115/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.4314 - accuracy: 0.8039\n",
      "Epoch 116/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.4203 - accuracy: 0.8025\n",
      "Epoch 117/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.4663 - accuracy: 0.7899\n",
      "Epoch 118/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.4260 - accuracy: 0.8123\n",
      "Epoch 119/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.4274 - accuracy: 0.7997\n",
      "Epoch 120/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.4449 - accuracy: 0.7941\n",
      "Epoch 121/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.4200 - accuracy: 0.8011\n",
      "Epoch 122/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.4273 - accuracy: 0.8039\n",
      "Epoch 123/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.4226 - accuracy: 0.8011\n",
      "Epoch 124/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.4290 - accuracy: 0.8011\n",
      "Epoch 125/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.4217 - accuracy: 0.7983\n",
      "Epoch 126/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.4216 - accuracy: 0.8179\n",
      "Epoch 127/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.4286 - accuracy: 0.8123\n",
      "Epoch 128/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.4493 - accuracy: 0.8025\n",
      "Epoch 129/300\n",
      "72/72 [==============================] - 0s 526us/step - loss: 0.4167 - accuracy: 0.8137\n",
      "Epoch 130/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.4476 - accuracy: 0.7969\n",
      "Epoch 131/300\n",
      "72/72 [==============================] - 0s 527us/step - loss: 0.4349 - accuracy: 0.8151\n",
      "Epoch 132/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.4460 - accuracy: 0.8025\n",
      "Epoch 133/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.4288 - accuracy: 0.7983\n",
      "Epoch 134/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.4547 - accuracy: 0.7829\n",
      "Epoch 135/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.4217 - accuracy: 0.8123\n",
      "Epoch 136/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.4290 - accuracy: 0.8109\n",
      "Epoch 137/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.4449 - accuracy: 0.8025\n",
      "Epoch 138/300\n",
      "72/72 [==============================] - 0s 762us/step - loss: 0.4071 - accuracy: 0.8179\n",
      "Epoch 139/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.4270 - accuracy: 0.8053\n",
      "Epoch 140/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.4156 - accuracy: 0.8053\n",
      "Epoch 141/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.4148 - accuracy: 0.8249\n",
      "Epoch 142/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.4104 - accuracy: 0.8123\n",
      "Epoch 143/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.4089 - accuracy: 0.8109\n",
      "Epoch 144/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.4048 - accuracy: 0.8235\n",
      "Epoch 145/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.4340 - accuracy: 0.8053\n",
      "Epoch 146/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.4214 - accuracy: 0.8137\n",
      "Epoch 147/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.3958 - accuracy: 0.8263\n",
      "Epoch 148/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.4496 - accuracy: 0.7871\n",
      "Epoch 149/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.4139 - accuracy: 0.8081\n",
      "Epoch 150/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.4075 - accuracy: 0.8151\n",
      "Epoch 151/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.4092 - accuracy: 0.8151\n",
      "Epoch 152/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.3934 - accuracy: 0.8235\n",
      "Epoch 153/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.3962 - accuracy: 0.8235\n",
      "Epoch 154/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.4051 - accuracy: 0.8235\n",
      "Epoch 155/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.4102 - accuracy: 0.8179\n",
      "Epoch 156/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.4068 - accuracy: 0.8123\n",
      "Epoch 157/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.4040 - accuracy: 0.8109\n",
      "Epoch 158/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.3968 - accuracy: 0.8235\n",
      "Epoch 159/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.3966 - accuracy: 0.8235\n",
      "Epoch 160/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 0s 540us/step - loss: 0.3937 - accuracy: 0.8263\n",
      "Epoch 161/300\n",
      "72/72 [==============================] - 0s 568us/step - loss: 0.3968 - accuracy: 0.8333\n",
      "Epoch 162/300\n",
      "72/72 [==============================] - 0s 637us/step - loss: 0.4168 - accuracy: 0.8137\n",
      "Epoch 163/300\n",
      "72/72 [==============================] - 0s 568us/step - loss: 0.3822 - accuracy: 0.8249\n",
      "Epoch 164/300\n",
      "72/72 [==============================] - 0s 582us/step - loss: 0.4223 - accuracy: 0.8109\n",
      "Epoch 165/300\n",
      "72/72 [==============================] - 0s 582us/step - loss: 0.3987 - accuracy: 0.8263\n",
      "Epoch 166/300\n",
      "72/72 [==============================] - 0s 568us/step - loss: 0.3814 - accuracy: 0.8235\n",
      "Epoch 167/300\n",
      "72/72 [==============================] - 0s 596us/step - loss: 0.3925 - accuracy: 0.8263\n",
      "Epoch 168/300\n",
      "72/72 [==============================] - 0s 568us/step - loss: 0.3888 - accuracy: 0.8235\n",
      "Epoch 169/300\n",
      "72/72 [==============================] - 0s 568us/step - loss: 0.4563 - accuracy: 0.7969\n",
      "Epoch 170/300\n",
      "72/72 [==============================] - 0s 568us/step - loss: 0.3910 - accuracy: 0.8235\n",
      "Epoch 171/300\n",
      "72/72 [==============================] - 0s 568us/step - loss: 0.3976 - accuracy: 0.8291\n",
      "Epoch 172/300\n",
      "72/72 [==============================] - 0s 609us/step - loss: 0.3850 - accuracy: 0.8277\n",
      "Epoch 173/300\n",
      "72/72 [==============================] - 0s 582us/step - loss: 0.3935 - accuracy: 0.8291\n",
      "Epoch 174/300\n",
      "72/72 [==============================] - 0s 554us/step - loss: 0.3963 - accuracy: 0.8319\n",
      "Epoch 175/300\n",
      "72/72 [==============================] - 0s 554us/step - loss: 0.3936 - accuracy: 0.8263\n",
      "Epoch 176/300\n",
      "72/72 [==============================] - 0s 554us/step - loss: 0.3828 - accuracy: 0.8277\n",
      "Epoch 177/300\n",
      "72/72 [==============================] - 0s 568us/step - loss: 0.3788 - accuracy: 0.8319\n",
      "Epoch 178/300\n",
      "72/72 [==============================] - 0s 596us/step - loss: 0.3956 - accuracy: 0.8207\n",
      "Epoch 179/300\n",
      "72/72 [==============================] - 0s 596us/step - loss: 0.3775 - accuracy: 0.8305\n",
      "Epoch 180/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.3843 - accuracy: 0.8221\n",
      "Epoch 181/300\n",
      "72/72 [==============================] - 0s 526us/step - loss: 0.3746 - accuracy: 0.8305\n",
      "Epoch 182/300\n",
      "72/72 [==============================] - 0s 554us/step - loss: 0.3805 - accuracy: 0.8333\n",
      "Epoch 183/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.3821 - accuracy: 0.8235\n",
      "Epoch 184/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.3673 - accuracy: 0.8417\n",
      "Epoch 185/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.3887 - accuracy: 0.8291\n",
      "Epoch 186/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.3810 - accuracy: 0.8221\n",
      "Epoch 187/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.4005 - accuracy: 0.8305\n",
      "Epoch 188/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.4179 - accuracy: 0.8095\n",
      "Epoch 189/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.4096 - accuracy: 0.8403\n",
      "Epoch 190/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.3999 - accuracy: 0.8277\n",
      "Epoch 191/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.3992 - accuracy: 0.8165\n",
      "Epoch 192/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.3929 - accuracy: 0.8221\n",
      "Epoch 193/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.4000 - accuracy: 0.8319\n",
      "Epoch 194/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.3762 - accuracy: 0.8333\n",
      "Epoch 195/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.3829 - accuracy: 0.8333\n",
      "Epoch 196/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.3832 - accuracy: 0.8207\n",
      "Epoch 197/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.3823 - accuracy: 0.8305\n",
      "Epoch 198/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.3926 - accuracy: 0.8333\n",
      "Epoch 199/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.3842 - accuracy: 0.8277\n",
      "Epoch 200/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.3722 - accuracy: 0.8403\n",
      "Epoch 201/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.3939 - accuracy: 0.8333\n",
      "Epoch 202/300\n",
      "72/72 [==============================] - 0s 526us/step - loss: 0.3779 - accuracy: 0.8403\n",
      "Epoch 203/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.3811 - accuracy: 0.8249\n",
      "Epoch 204/300\n",
      "72/72 [==============================] - 0s 526us/step - loss: 0.3865 - accuracy: 0.8291\n",
      "Epoch 205/300\n",
      "72/72 [==============================] - 0s 526us/step - loss: 0.3755 - accuracy: 0.8333\n",
      "Epoch 206/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.3832 - accuracy: 0.8319\n",
      "Epoch 207/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.3753 - accuracy: 0.8291\n",
      "Epoch 208/300\n",
      "72/72 [==============================] - 0s 540us/step - loss: 0.3706 - accuracy: 0.8249\n",
      "Epoch 209/300\n",
      "72/72 [==============================] - 0s 526us/step - loss: 0.3913 - accuracy: 0.8193\n",
      "Epoch 210/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.4351 - accuracy: 0.8011\n",
      "Epoch 211/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.4620 - accuracy: 0.7927\n",
      "Epoch 212/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.3861 - accuracy: 0.8291\n",
      "Epoch 213/300\n",
      "72/72 [==============================] - 0s 540us/step - loss: 0.3827 - accuracy: 0.8291\n",
      "Epoch 214/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.3947 - accuracy: 0.8277\n",
      "Epoch 215/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.3697 - accuracy: 0.8249\n",
      "Epoch 216/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.3720 - accuracy: 0.8361\n",
      "Epoch 217/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.3815 - accuracy: 0.8263\n",
      "Epoch 218/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.3955 - accuracy: 0.8193\n",
      "Epoch 219/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.3752 - accuracy: 0.8347\n",
      "Epoch 220/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.3763 - accuracy: 0.8277\n",
      "Epoch 221/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.3701 - accuracy: 0.8277\n",
      "Epoch 222/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.3835 - accuracy: 0.8319\n",
      "Epoch 223/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.3669 - accuracy: 0.8319\n",
      "Epoch 224/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.3624 - accuracy: 0.8263\n",
      "Epoch 225/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.3798 - accuracy: 0.8277\n",
      "Epoch 226/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.3705 - accuracy: 0.8417\n",
      "Epoch 227/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.3820 - accuracy: 0.8361\n",
      "Epoch 228/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.3821 - accuracy: 0.8403\n",
      "Epoch 229/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.3694 - accuracy: 0.8361\n",
      "Epoch 230/300\n",
      "72/72 [==============================] - 0s 526us/step - loss: 0.3626 - accuracy: 0.8347\n",
      "Epoch 231/300\n",
      "72/72 [==============================] - 0s 540us/step - loss: 0.3702 - accuracy: 0.8319\n",
      "Epoch 232/300\n",
      "72/72 [==============================] - 0s 540us/step - loss: 0.3598 - accuracy: 0.8515\n",
      "Epoch 233/300\n",
      "72/72 [==============================] - 0s 526us/step - loss: 0.3725 - accuracy: 0.8431\n",
      "Epoch 234/300\n",
      "72/72 [==============================] - 0s 540us/step - loss: 0.3687 - accuracy: 0.8389\n",
      "Epoch 235/300\n",
      "72/72 [==============================] - 0s 596us/step - loss: 0.3587 - accuracy: 0.8333\n",
      "Epoch 236/300\n",
      "72/72 [==============================] - 0s 554us/step - loss: 0.3572 - accuracy: 0.8389\n",
      "Epoch 237/300\n",
      "72/72 [==============================] - 0s 568us/step - loss: 0.3510 - accuracy: 0.8445\n",
      "Epoch 238/300\n",
      "72/72 [==============================] - 0s 568us/step - loss: 0.3606 - accuracy: 0.8389\n",
      "Epoch 239/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 0s 540us/step - loss: 0.3678 - accuracy: 0.8347\n",
      "Epoch 240/300\n",
      "72/72 [==============================] - 0s 540us/step - loss: 0.3546 - accuracy: 0.8445\n",
      "Epoch 241/300\n",
      "72/72 [==============================] - 0s 540us/step - loss: 0.3634 - accuracy: 0.8445\n",
      "Epoch 242/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.3563 - accuracy: 0.8501\n",
      "Epoch 243/300\n",
      "72/72 [==============================] - 0s 554us/step - loss: 0.3987 - accuracy: 0.8319\n",
      "Epoch 244/300\n",
      "72/72 [==============================] - 0s 540us/step - loss: 0.3681 - accuracy: 0.8375\n",
      "Epoch 245/300\n",
      "72/72 [==============================] - 0s 526us/step - loss: 0.3739 - accuracy: 0.8263\n",
      "Epoch 246/300\n",
      "72/72 [==============================] - 0s 554us/step - loss: 0.3653 - accuracy: 0.8361\n",
      "Epoch 247/300\n",
      "72/72 [==============================] - 0s 540us/step - loss: 0.3689 - accuracy: 0.8277\n",
      "Epoch 248/300\n",
      "72/72 [==============================] - 0s 526us/step - loss: 0.4005 - accuracy: 0.8221\n",
      "Epoch 249/300\n",
      "72/72 [==============================] - 0s 540us/step - loss: 0.3625 - accuracy: 0.8389\n",
      "Epoch 250/300\n",
      "72/72 [==============================] - 0s 540us/step - loss: 0.3682 - accuracy: 0.8333\n",
      "Epoch 251/300\n",
      "72/72 [==============================] - 0s 526us/step - loss: 0.3601 - accuracy: 0.8291\n",
      "Epoch 252/300\n",
      "72/72 [==============================] - 0s 568us/step - loss: 0.3602 - accuracy: 0.8403\n",
      "Epoch 253/300\n",
      "72/72 [==============================] - 0s 720us/step - loss: 0.3520 - accuracy: 0.8501\n",
      "Epoch 254/300\n",
      "72/72 [==============================] - 0s 665us/step - loss: 0.3649 - accuracy: 0.8375\n",
      "Epoch 255/300\n",
      "72/72 [==============================] - 0s 582us/step - loss: 0.3553 - accuracy: 0.8333\n",
      "Epoch 256/300\n",
      "72/72 [==============================] - 0s 582us/step - loss: 0.3479 - accuracy: 0.8487\n",
      "Epoch 257/300\n",
      "72/72 [==============================] - 0s 554us/step - loss: 0.3555 - accuracy: 0.8431\n",
      "Epoch 258/300\n",
      "72/72 [==============================] - 0s 568us/step - loss: 0.3578 - accuracy: 0.8417\n",
      "Epoch 259/300\n",
      "72/72 [==============================] - 0s 568us/step - loss: 0.3575 - accuracy: 0.8431\n",
      "Epoch 260/300\n",
      "72/72 [==============================] - 0s 526us/step - loss: 0.3599 - accuracy: 0.8361\n",
      "Epoch 261/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.3551 - accuracy: 0.8431\n",
      "Epoch 262/300\n",
      "72/72 [==============================] - 0s 526us/step - loss: 0.3686 - accuracy: 0.8431\n",
      "Epoch 263/300\n",
      "72/72 [==============================] - 0s 554us/step - loss: 0.3774 - accuracy: 0.8305\n",
      "Epoch 264/300\n",
      "72/72 [==============================] - 0s 526us/step - loss: 0.3899 - accuracy: 0.8221\n",
      "Epoch 265/300\n",
      "72/72 [==============================] - 0s 554us/step - loss: 0.3556 - accuracy: 0.8389\n",
      "Epoch 266/300\n",
      "72/72 [==============================] - 0s 526us/step - loss: 0.3625 - accuracy: 0.8389\n",
      "Epoch 267/300\n",
      "72/72 [==============================] - 0s 526us/step - loss: 0.3921 - accuracy: 0.8263\n",
      "Epoch 268/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.3666 - accuracy: 0.8333\n",
      "Epoch 269/300\n",
      "72/72 [==============================] - 0s 526us/step - loss: 0.3585 - accuracy: 0.8431\n",
      "Epoch 270/300\n",
      "72/72 [==============================] - 0s 526us/step - loss: 0.3534 - accuracy: 0.8417\n",
      "Epoch 271/300\n",
      "72/72 [==============================] - 0s 526us/step - loss: 0.3577 - accuracy: 0.8277\n",
      "Epoch 272/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.3456 - accuracy: 0.8459\n",
      "Epoch 273/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.3559 - accuracy: 0.8375\n",
      "Epoch 274/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.3402 - accuracy: 0.8571\n",
      "Epoch 275/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.3637 - accuracy: 0.8375\n",
      "Epoch 276/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.3741 - accuracy: 0.8347\n",
      "Epoch 277/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.4094 - accuracy: 0.8207\n",
      "Epoch 278/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.3501 - accuracy: 0.8585\n",
      "Epoch 279/300\n",
      "72/72 [==============================] - 0s 526us/step - loss: 0.3653 - accuracy: 0.8305\n",
      "Epoch 280/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.3615 - accuracy: 0.8361\n",
      "Epoch 281/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.3565 - accuracy: 0.8487\n",
      "Epoch 282/300\n",
      "72/72 [==============================] - 0s 512us/step - loss: 0.3603 - accuracy: 0.8361\n",
      "Epoch 283/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.3583 - accuracy: 0.8375\n",
      "Epoch 284/300\n",
      "72/72 [==============================] - 0s 540us/step - loss: 0.3368 - accuracy: 0.8529\n",
      "Epoch 285/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.3730 - accuracy: 0.8333\n",
      "Epoch 286/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.3545 - accuracy: 0.8361\n",
      "Epoch 287/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.3519 - accuracy: 0.8403\n",
      "Epoch 288/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.3722 - accuracy: 0.8249\n",
      "Epoch 289/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.3629 - accuracy: 0.8403\n",
      "Epoch 290/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.3632 - accuracy: 0.8347\n",
      "Epoch 291/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.3514 - accuracy: 0.8417\n",
      "Epoch 292/300\n",
      "72/72 [==============================] - 0s 485us/step - loss: 0.3620 - accuracy: 0.8235\n",
      "Epoch 293/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.3375 - accuracy: 0.8501\n",
      "Epoch 294/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.3539 - accuracy: 0.8487\n",
      "Epoch 295/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.3725 - accuracy: 0.8291\n",
      "Epoch 296/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.3769 - accuracy: 0.8361\n",
      "Epoch 297/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.3463 - accuracy: 0.8431\n",
      "Epoch 298/300\n",
      "72/72 [==============================] - 0s 512us/step - loss: 0.3923 - accuracy: 0.8417\n",
      "Epoch 299/300\n",
      "72/72 [==============================] - 0s 513us/step - loss: 0.3432 - accuracy: 0.8501\n",
      "Epoch 300/300\n",
      "72/72 [==============================] - 0s 499us/step - loss: 0.3751 - accuracy: 0.8333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x181ca3c5250>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(200, input_dim=len(x.keys()), activation='relu'))\n",
    "model.add(Dense(40, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 모델 학습과정 설정\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(lr=0.001), metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습시키기\n",
    "model.fit(x, y, epochs=300, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d9f78ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)\n",
    "pred = []\n",
    "for i in predictions:\n",
    "    if i[0] < 0.5: i[0] = 0\n",
    "    else: i[0] = 1\n",
    "    pred.append(int(i[0]))\n",
    "submission = pd.DataFrame(data = zip(x_test[\"PassengerId\"], pred), columns = ['PassengerId', 'Survived'])\n",
    "submission.to_csv('./submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aa25d5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''강사님이 작성하신 파일\n",
    "predictions = model.predict(x_test)\n",
    "predicted = tf.cast(predictions > 0.5, dtype=tf.int32)\n",
    "predicted = predicted.numpy()\n",
    "\n",
    "submission = pd.DataFrame({\"PassengerId\" : x_test['PassengerId'], 'Survived' : predicted.flatten()})\n",
    "submission.to_csv('./submission.csv', index = False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d9e18737",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
